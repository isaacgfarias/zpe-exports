# %%
import polars as pl
import streamlit as st
import plotly.express as px
import os
import pandas as pd
import numpy as np  # Adicionado para opera√ß√µes num√©ricas robustas

# Nota: As classes ComexStat, Comtrade e HarvardDataverse foram mantidas na importa√ß√£o
from comexstat import Comexstat
from comtrade import Comtrade
from dataverse import HarvardDataverse

# --- Fun√ß√µes Auxiliares de Formata√ß√£o e C√°lculo ---


def format_fob_metric(value):
    """
    Formata um valor num√©rico para uma string no formato monet√°rio (US$)
    com sufixos Mi (Milh√µes), Bi (Bilh√µes) ou Tri (Trilh√µes),
    utilizando v√≠rgula como separador decimal.
    """
    if value >= 1e12:
        display = f"${value / 1e12:,.2f} Tri"
    elif value >= 1e9:
        display = f"${value / 1e9:,.2f} Bi"
    elif value >= 1e6:
        display = f"${value / 1e6:,.2f} Mi"
    else:
        display = f"${value:,.2f}"

    # Ajuste de formata√ß√£o (troca . por , para decimal e , por . para milhar)
    return display.replace(",", "_TEMP_").replace(".", ",").replace("_TEMP_", ".")


@st.cache_data
def calcular_vcr_ceara_brasil(df_comexstat):
    """
    Calcula o VCR (Vantagem Comparativa Revelada) do Cear√° em rela√ß√£o ao Brasil
    para cada 'headingCode' (setor i), utilizando o Valor FOB (metricFOB).
    """
    # Filtrar dados v√°lidos e garantir coer√™ncia de tipos
    df_comexstat_valid = df_comexstat[df_comexstat["metricFOB"] > 0].copy()
    df_comexstat_valid["headingCode"] = df_comexstat_valid["headingCode"].astype(str)

    # 1. Total das exporta√ß√µes (FOB) para o Brasil e Cear√°
    X_total_brasil = df_comexstat_valid["metricFOB"].sum()
    df_ceara = df_comexstat_valid[df_comexstat_valid["state"] == "Cear√°"].copy()
    X_total_ceara = df_ceara["metricFOB"].sum()

    if X_total_brasil == 0 or X_total_ceara == 0 or df_comexstat_valid.empty:
        # Retorna estrutura vazia se n√£o houver dados v√°lidos para c√°lculo
        return pd.DataFrame(columns=["headingCode", "VCR_Ceara_Brasil"])

    # 2. Exporta√ß√µes por setor no Cear√° (Xi_Ceara)
    df_xi_ceara = df_ceara.groupby("headingCode")["metricFOB"].sum().reset_index()
    df_xi_ceara = df_xi_ceara.rename(columns={"metricFOB": "Xi_Ceara"})

    # 3. Exporta√ß√µes por setor no Brasil (Xi_Brasil)
    df_xi_brasil = (
        df_comexstat_valid.groupby("headingCode")["metricFOB"].sum().reset_index()
    )
    df_xi_brasil = df_xi_brasil.rename(columns={"metricFOB": "Xi_Brasil"})

    # 4. Jun√ß√£o dos dados
    df_vcr = df_xi_ceara.merge(df_xi_brasil, on="headingCode", how="outer").fillna(0)

    # 5. C√°lculo da VCR
    parcela_ceara = df_vcr["Xi_Ceara"] / X_total_ceara
    parcela_brasil = df_vcr["Xi_Brasil"] / X_total_brasil

    # Uso de np.where para evitar divis√£o por zero de forma robusta e vetorial
    df_vcr["VCR_Ceara_Brasil"] = np.where(
        parcela_brasil > 0, parcela_ceara / parcela_brasil, 0
    )

    return df_vcr[["headingCode", "VCR_Ceara_Brasil"]]


@st.cache_data
def obter_vcr_brasil_mundo(df_harvard):
    """
    Obt√©m o VCR do Brasil em rela√ß√£o ao Mundo a partir da coluna 'export_rca'
    do Harvard Dataverse, por 'product_hs92_code' (setor i).
    """
    df_vcr = df_harvard.rename(
        columns={"product_hs92_code": "headingCode", "export_rca": "VCR_Brasil_Mundo"}
    ).copy()

    # Normaliza o c√≥digo HS de 6 d√≠gitos para 4 para unifica√ß√£o com ComexStat
    df_vcr["headingCode"] = df_vcr["headingCode"].astype(str).str[:4]

    # Calcula a m√©dia do VCR ao longo dos anos para cada produto de 4 d√≠gitos
    df_vcr = df_vcr.groupby("headingCode")["VCR_Brasil_Mundo"].mean().reset_index()

    return df_vcr


@st.cache_data
def obter_pci_e_distancia(df_harvard):
    """
    Obt√©m o PCI e a Dist√¢ncia para cada setor (product_hs92_code).
    """
    df_metrics = df_harvard.rename(
        columns={
            "product_hs92_code": "headingCode",
            "pci": "PCI",
            "distance": "Distancia_Parceiros",
        }
    ).copy()

    # Normaliza o c√≥digo HS de 6 d√≠gitos para 4 para unifica√ß√£o com ComexStat
    df_metrics["headingCode"] = df_metrics["headingCode"].astype(str).str[:4]

    # Calcula a m√©dia do PCI e da Dist√¢ncia ao longo dos anos para cada produto de 4 d√≠gitos
    df_metrics = (
        df_metrics.groupby("headingCode")
        .agg({"PCI": "mean", "Distancia_Parceiros": "mean"})
        .reset_index()
    )

    return df_metrics


@st.cache_data
def calcular_vcr_dentro_selecao(df_comex_filtrado, df_comex_nacional):
    """
    Calcula a VCR (Vantagem Comparativa Revelada) dos produtos (headings)
    em cada estado.
    - Se apenas 1 estado for selecionado, compara-o contra o contexto NACIONAL.
    - Se m√∫ltiplos estados forem selecionados, compara-o contra o CONJUNTO FILTRADO.
    """
    import numpy as np
    import pandas as pd

    if df_comex_filtrado.empty:
        return pd.DataFrame(columns=["state", "headingCode", "heading", "VCR"])

    df_comex_filtrado = df_comex_filtrado.copy()
    df_comex_filtrado["headingCode"] = df_comex_filtrado["headingCode"].astype(str)

    selected_states = df_comex_filtrado["state"].unique()

    # ----------------------------------------------------------------------
    # 1. DEFINI√á√ÉO DA BASE DE COMPARA√á√ÉO (DENOMINADOR)
    # ----------------------------------------------------------------------
    if len(selected_states) == 1:
        # CORRE√á√ÉO: Se apenas um estado, a base de compara√ß√£o √© o CONTEXTO NACIONAL
        df_base_comparacao = df_comex_nacional.copy()

    else:
        # Se m√∫ltiplos estados, a base de compara√ß√£o √© a SOMA DOS ESTADOS SELECIONADOS
        df_base_comparacao = df_comex_filtrado.copy()

    # C√°lculo do Denominador da VCR

    # Total das exporta√ß√µes (FOB) para o CONTEXTO DE COMPARA√á√ÉO
    X_total_comparacao = df_base_comparacao["metricFOB"].sum()

    # Exporta√ß√£o do Produto no Contexto de Compara√ß√£o (Xi_comparacao)
    df_xi_comparacao = (
        df_base_comparacao.groupby("headingCode")["metricFOB"].sum().reset_index()
    )
    df_xi_comparacao = df_xi_comparacao.rename(columns={"metricFOB": "Xi_comparacao"})

    if X_total_comparacao == 0:
        # Retorna VCR 0 se o total for 0
        df_comex_filtrado["VCR"] = 0.0
        return df_comex_filtrado[["state", "headingCode", "metricFOB", "VCR"]].copy()

    # Taxa de Exporta√ß√£o Global no Contexto de Compara√ß√£o (Denominador da VCR)
    df_xi_comparacao["Tx_Global_Contexto"] = (
        df_xi_comparacao["Xi_comparacao"] / X_total_comparacao
    )

    # ----------------------------------------------------------------------
    # 2. C√ÅLCULO DO NUMERADOR DA VCR (Taxa Local)
    # ----------------------------------------------------------------------

    # Agrega√ß√£o por Estado e Produto (X_i, estado)
    df_export_estado = (
        df_comex_filtrado.groupby(["state", "headingCode"])["metricFOB"]
        .sum()
        .reset_index()
    )

    # Total das exporta√ß√µes por Estado (X_total_estado)
    df_export_total_estado = (
        df_comex_filtrado.groupby("state")["metricFOB"].sum().reset_index()
    )
    df_export_total_estado = df_export_total_estado.rename(
        columns={"metricFOB": "X_total_estado"}
    )

    # Jun√ß√£o dos dados
    df_vcr_calc = df_export_estado.merge(df_export_total_estado, on="state", how="left")
    df_vcr_calc = df_vcr_calc.merge(
        df_xi_comparacao[["headingCode", "Tx_Global_Contexto"]],
        on="headingCode",
        how="left",
    ).fillna(0)

    # C√°lculo da Taxa de Exporta√ß√£o Local (Numerador da VCR)
    df_vcr_calc["Tx_Local"] = df_vcr_calc["metricFOB"] / df_vcr_calc["X_total_estado"]

    # ----------------------------------------------------------------------
    # 3. C√ÅLCULO FINAL
    # ----------------------------------------------------------------------
    df_vcr_calc["VCR"] = np.where(
        df_vcr_calc["Tx_Global_Contexto"] > 0,
        df_vcr_calc["Tx_Local"] / df_vcr_calc["Tx_Global_Contexto"],
        0.0,
    )

    # Reagrupar para ter uma linha por state/heading/headingCode e manter VCR
    df_result = df_vcr_calc[["state", "headingCode", "metricFOB", "VCR"]].copy()

    # Adicionar a descri√ß√£o (heading) de volta, usando a base nacional para garantir todos os headings
    df_headings = df_comex_nacional[["headingCode", "heading"]].drop_duplicates()
    df_result = df_result.merge(df_headings, on="headingCode", how="left")

    return df_result[df_result["VCR"] > 0].sort_values(by="VCR", ascending=False)


# ==============================================================================
# NOVAS FUN√á√ïES EXIGIDAS PELA L√ìGICA DO DOCUMENTO ANEXO
# ==============================================================================


def normalizar_vcr(df: pd.DataFrame, coluna_vcr: str) -> pd.DataFrame:
    """
    Normaliza os valores de uma coluna de VCR para um intervalo de 0 a 1.
    F√≥rmula: VCRi^Norm = (VCRi - VCRmin) / (VCRmax - VCRmin)
    Aplica-se apenas a valores num√©ricos v√°lidos.
    """
    coluna_norm = coluna_vcr + "_NORM"

    # Converte para num√©rico e remove NaNs para o c√°lculo min/max
    vcr_numeric = pd.to_numeric(df[coluna_vcr], errors="coerce").dropna()

    if vcr_numeric.empty:
        df[coluna_norm] = 0.0
        return df

    vcr_min = vcr_numeric.min()
    vcr_max = vcr_numeric.max()

    if vcr_max == vcr_min:
        df[coluna_norm] = 0.0
    else:
        # Aplica a normaliza√ß√£o, tratando NaNs (que ser√£o preenchidos depois)
        df[coluna_norm] = (df[coluna_vcr].astype(float) - vcr_min) / (vcr_max - vcr_min)

    return df


def calcular_vcr_ajustado(df_metrics: pd.DataFrame) -> pd.DataFrame:
    """
    IMPLEMENTA√á√ÉO PLACEHOLDER (VCR Ajustado).
    O c√°lculo real do VCR Ajustado (baseado em Empregos, Empresas, etc.) exige
    dados municipais/setoriais que n√£o s√£o carregados em 'app.py' (apenas Comex, Harvard, Comtrade).

    Esta fun√ß√£o implementa um PLACEHOLDER simulando o VCR Ajustado (VCR_AJUSTADO)
    e o VCR Ajustado Normalizado (VCR_AJUSTADO_NORM) baseado no PCI e VCR Cear√°/Brasil,
    para que a l√≥gica de normaliza√ß√£o possa ser demonstrada.
    """
    df = df_metrics.copy()

    # Placeholder: VCR_AJUSTADO √© uma combina√ß√£o do VCR tradicional e PCI
    # Isso simula um √≠ndice de complexidade local/setorial.
    vcr_ce_br = pd.to_numeric(df["VCR_Ceara_Brasil"], errors="coerce").fillna(0)
    pci = pd.to_numeric(df["PCI"], errors="coerce").fillna(0)

    # Simula√ß√£o da f√≥rmula: (VCR_CE/BR + PCI) / 2
    df["VCR_AJUSTADO"] = np.where(
        (vcr_ce_br > 1) & (pci.notna()),
        (vcr_ce_br + pci) / 2,  # Combina√ß√£o quando h√° vantagem
        vcr_ce_br,  # Apenas VCR quando n√£o h√° vantagem (ou PCI ausente)
    )

    # Normaliza√ß√£o conforme documento
    df = normalizar_vcr(df, "VCR_AJUSTADO")

    return df


def calcular_indice_prioridade_ajustado(df: pd.DataFrame, pesos: dict) -> pd.DataFrame:
    """
    Calcula o √çndice de Prioridade Ajustado utilizando as m√©tricas normalizadas
    e os pesos definidos pelo usu√°rio.
    """
    df_calc = df.copy()

    # Certifica-se de que as colunas normalizadas s√£o float, tratando NaNs
    df_calc["VCR_CE_NORM"] = pd.to_numeric(
        df_calc["VCR_Ceara_Brasil_NORM"], errors="coerce"
    ).fillna(0)
    df_calc["VCR_BR_NORM"] = pd.to_numeric(
        df_calc["VCR_Brasil_Mundo_NORM"], errors="coerce"
    ).fillna(0)
    df_calc["VCR_AJ_NORM"] = pd.to_numeric(
        df_calc["VCR_AJUSTADO_NORM"], errors="coerce"
    ).fillna(0)
    df_calc["PCI_NORM"] = pd.to_numeric(df_calc["PCI_NORM"], errors="coerce").fillna(0)

    # Normaliza√ß√£o da Dist√¢ncia: Inverter a l√≥gica. Dist√¢ncias menores devem ter valor maior (proximidade).
    # Assumimos que a Dist√¢ncia (m√©trica bruta) j√° foi normalizada de 0 a 1 em "Distancia_Parceiros_NORM"
    # Se Distancia_Parceiros_NORM for a proximidade:
    dist_norm = pd.to_numeric(
        df_calc["Distancia_Parceiros_NORM"], errors="coerce"
    ).fillna(0)

    # Se Distancia_Parceiros_NORM for a dist√¢ncia (quanto maior, pior):
    # Vamos reverter (1 - Dist√¢ncia Normalizada) para obter a Proximidade Normalizada
    proximidade_norm = 1 - dist_norm

    # C√°lculo do √çndice de Prioridade Ajustado (Soma Ponderada)
    # VCR_estadual + VCR_pa√≠s + VCR_Ajustado s√£o m√©tricas positivas (quanto maior, melhor)
    # PCI √© m√©trica positiva (quanto maior, melhor)
    # Dist√¢ncia √© m√©trica negativa (quanto maior, pior) -> usamos Proximidade

    # Peso total para garantir que a soma das VCRs seja ponderada corretamente
    peso_vcr_total = pesos["vcr_ceara"] + pesos["vcr_brasil"] + pesos["vcr_ajustado"]

    # Normaliza√ß√£o dos pesos VCRs para soma 1 (para o subconjunto VCR)
    if peso_vcr_total > 0:
        peso_vcr_ceara = pesos["vcr_ceara"] / peso_vcr_total
        peso_vcr_brasil = pesos["vcr_brasil"] / peso_vcr_total
        peso_vcr_ajustado = pesos["vcr_ajustado"] / peso_vcr_total
    else:
        # Se os pesos VCRs forem zero, distribu√≠mos igualmente para evitar NaN
        peso_vcr_ceara = peso_vcr_brasil = peso_vcr_ajustado = 1 / 3

    # √çndice VCR Composto (normalizado)
    indice_vcr = (
        (df_calc["VCR_CE_NORM"] * peso_vcr_ceara)
        + (df_calc["VCR_BR_NORM"] * peso_vcr_brasil)
        + (df_calc["VCR_AJ_NORM"] * peso_vcr_ajustado)
    )

    # √çndice Final: Combina√ß√£o dos 3 componentes (VCR_Composto, PCI, Proximidade)
    # Assumimos que os pesos PCI, Distancia e o peso VCR_total (1) s√£o os pesos finais

    # Normalizando os 3 grandes grupos de pesos (VCR Total, PCI, Dist√¢ncia) para somarem 1
    peso_total_geral = 1 + pesos["pci"] + pesos["distancia"]

    peso_vcr_composto = 1 / peso_total_geral  # Peso do subconjunto VCR
    peso_pci = pesos["pci"] / peso_total_geral
    peso_distancia = pesos["distancia"] / peso_total_geral

    df_calc["INDICE_PRIORIDADE_AJUSTADO"] = (
        (indice_vcr * peso_vcr_composto)
        + (df_calc["PCI_NORM"] * peso_pci)
        + (proximidade_norm * peso_distancia)
    )

    return df_calc


# ==============================================================================
# FIM DAS NOVAS FUN√á√ïES
# ==============================================================================


# %%
# Configura√ß√£o inicial do Streamlit
st.set_page_config(
    page_title="Dashboard Com√©rcio Internacional",
    layout="wide",
    # Ocultando a sidebar para manter a est√©tica original do seu c√≥digo,
    # j√° que os filtros foram movidos para o expander
    initial_sidebar_state="collapsed",
)


COMEXSTAT_PATH = "resources/comexstat_data.csv"
HARVARD_PATH = "resources/harvard_data.csv"
COMTRADE_PATH = "resources/comtrade_data.csv"

# Verifica√ß√£o e carregamento dos dados
if not all(
    os.path.exists(path) for path in [COMEXSTAT_PATH, HARVARD_PATH, COMTRADE_PATH]
):
    st.error(
        "Arquivos de dados n√£o encontrados. Por favor, execute o script 'main.py' primeiro para gerar os arquivos CSV."
    )
    st.stop()


@st.cache_data
def load_data(path):
    """
    Carrega dados de um arquivo CSV usando Polars, converte para Pandas e,
    para ComexStat, aplica a corre√ß√£o de desalinhamento de colunas.
    """
    # Schema de leitura for√ßada
    if "harvard_data.csv" in path:
        custom_schema = {
            "country_id": pl.Int8,
            "country_iso3_code": pl.Utf8,
            "product_id": pl.Int64,
            "product_hs92_code": pl.Utf8,
            "year": pl.Int64,
            "export_value": pl.Int64,
            "import_value": pl.Int64,
            "global_share": pl.Float64,
            "export_rca": pl.Float64,
            "distance": pl.Float64,
            "cog": pl.Float64,
            "pci": pl.Float64,
        }
    elif "comexstat_data.csv" in path:
        custom_schema = {
            "year": pl.Int64,
            "state": pl.Utf8,
            "headingCode": pl.Utf8,
            "heading": pl.Utf8,
            "metricFOB": pl.Int64,
        }
    elif "comtrade_data.csv" in path:
        custom_schema = {
            "typeCode": pl.Utf8,
            "freqCode": pl.Utf8,
            "refPeriodId": pl.Int64,
            "refYear": pl.Int64,
            "refMonth": pl.Int64,
            "period": pl.Int64,
            "reporterCode": pl.Int64,
            "reporterISO": pl.Utf8,  # Inferred as string/code
            "reporterDesc": pl.Utf8,  # Inferred as string/description
            "flowCode": pl.Utf8,
            "flowDesc": pl.Utf8,  # Inferred as string/description
            "partnerCode": pl.Int64,
            "partnerISO": pl.Utf8,  # Inferred as string/code
            "partnerDesc": pl.Utf8,  # Inferred as string/description
            "partner2Code": pl.Int64,
            "partner2ISO": pl.Utf8,  # Inferred as string/code
            "partner2Desc": pl.Utf8,  # Inferred as string/description
            "classificationCode": pl.Utf8,
            "classificationSearchCode": pl.Utf8,
            "isOriginalClassification": pl.Boolean,
            "cmdCode": pl.Utf8,
            "cmdDesc": pl.Utf8,  # Inferred as string/description
            "aggrLevel": pl.Int64,  # Inferred as integer level
            "isLeaf": pl.Boolean,  # Inferred as a boolean flag
            "customsCode": pl.Utf8,
            "customsDesc": pl.Utf8,  # Inferred as string/description
            "mosCode": pl.Int64,
            "motCode": pl.Int64,
            "motDesc": pl.Utf8,  # Inferred as string/description
            "qtyUnitCode": pl.Int64,
            "qtyUnitAbbr": pl.Utf8,  # Inferred as string/abbreviation
            "qty": pl.Float64,  # Inferred as a measurable quantity
            "isQtyEstimated": pl.Boolean,
            "altQtyUnitCode": pl.Int64,
            "altQtyUnitAbbr": pl.Utf8,  # Inferred as string/abbreviation
            "altQty": pl.Float64,  # Inferred as a measurable quantity
            "isAltQtyEstimated": pl.Boolean,
            "netWgt": pl.Float64,
            "isNetWgtEstimated": pl.Boolean,
            "grossWgt": pl.Float64,
            "isGrossWgtEstimated": pl.Boolean,
            "cifvalue": pl.Float64,  # Inferred as a monetary value
            "fobvalue": pl.Float64,
            "primaryValue": pl.Float64,
            "legacyEstimationFlag": pl.Int64,
            "isReported": pl.Boolean,
            "isAggregate": pl.Boolean,
        }
    else:
        custom_schema = None

    # 1. Leitura usando Polars
    df_pl = pl.read_csv(
        path, schema=custom_schema, ignore_errors=True, truncate_ragged_lines=True
    )

    # 2. Convers√£o para Pandas
    df_pd = df_pl.to_pandas()

    return df_pd


# Carregar os tr√™s dataframes, usando a fun√ß√£o cacheada e tipagem correta
comexstat_df = load_data(COMEXSTAT_PATH)
harvard_df = load_data(HARVARD_PATH)
comtrade_df = load_data(COMTRADE_PATH)

# Garantir a coer√™ncia do tipo 'headingCode' para merge na An√°lise Comparativa
comexstat_df["headingCode"] = comexstat_df["headingCode"].astype(str)

# %%
st.title("Dashboard de An√°lise de Com√©rcio Internacional üìä")
st.markdown(
    "Este painel apresenta dados de com√©rcio extra√≠dos de fontes distintas: ComexStat, Harvard Dataverse e Comtrade da ONU."
)

# Cria√ß√£o das abas
tab_comex, tab_harvard, tab_comtrade, tab_compare = st.tabs(
    ["ComexStat", "Harvard Dataverse", "Comtrade", "An√°lise Comparativa"]
)


# %%
# Aba ComexStat
with tab_comex:
    st.header("Dados do ComexStat")

    # --- FILTROS DENTRO DA ABA ---
    with st.expander("Op√ß√µes de Filtragem", expanded=True):
        col_state, col_year, col_hs = st.columns(3)

        # 1. Filtro de Estado (UF) - Default: 'CE'
        states = sorted(comexstat_df["state"].dropna().unique().tolist())
        default_state = ["Cear√°"] if "Cear√°" in states else states[:1]

        selected_states = col_state.multiselect(
            "Selecione o(s) Estado(s)",
            options=states,
            default=default_state,
            key="comex_state_select",
            help="Selecione um ou mais estados para a an√°lise.",
        )

        # 2. Filtro de Ano
        years = sorted(comexstat_df["year"].dropna().unique().astype(int).tolist())
        selected_years = col_year.multiselect(
            "Selecione o(s) Ano(s)",
            years,
            default=years,
            key="comex_year_select",
            help="Selecione um ou mais anos para a an√°lise.",
        )

        # 3. Filtro de C√≥digo HS
        df_for_hs_options = comexstat_df.copy()
        if selected_states:
            df_for_hs_options = df_for_hs_options[
                df_for_hs_options["state"].isin(selected_states)
            ]
        if selected_years:
            df_for_hs_options = df_for_hs_options[
                df_for_hs_options["year"].isin(selected_years)
            ]

        df_for_hs_options["HS_Desc"] = (
            df_for_hs_options["headingCode"].astype(str)
            + " - "
            + df_for_hs_options["heading"].astype(str).str[:50]
            + "..."
        )
        products_options = sorted(
            df_for_hs_options["HS_Desc"].dropna().unique().tolist()
        )

        selected_hs_desc = col_hs.multiselect(
            "Selecione o(s) C√≥digo(s) HS",
            products_options,
            key="comex_hs_select",
            help="Filtra c√≥digos HS com base na sele√ß√£o de estado/ano.",
        )
        selected_products = [desc.split(" - ")[0] for desc in selected_hs_desc]

    # --- APLICA√á√ÉO DOS FILTROS ---
    comexstat_filtered = comexstat_df.copy()

    if selected_states:
        comexstat_filtered = comexstat_filtered[
            comexstat_filtered["state"].isin(selected_states)
        ]

    if selected_years:
        comexstat_filtered = comexstat_filtered[
            comexstat_filtered["year"].isin(selected_years)
        ]

    if selected_products:
        comexstat_filtered = comexstat_filtered[
            comexstat_filtered["headingCode"].isin(selected_products)
        ]

    # --- BLOCO DE M√âTRICAS ANAL√çTICAS ---
    # (Mantido como antes, usando o total FOB da sele√ß√£o)
    col_metric1, col_metric2, col_metric3 = st.columns(3)

    total_selected_fob = comexstat_filtered["metricFOB"].sum()
    total_brasil_fob = comexstat_df["metricFOB"].sum()
    total_mundo_display = "$49,71 Tri"

    with col_metric1:
        st.subheader("Total de Exporta√ß√µes (Sele√ß√£o Atual)")
        st.metric("Total (US$)", format_fob_metric(total_selected_fob))

    with col_metric2:
        st.subheader("Total de Exporta√ß√µes do Brasil")
        st.metric("Total (US$)", format_fob_metric(total_brasil_fob))

    with col_metric3:
        st.subheader("Total de Exporta√ß√µes do Mundo")
        st.metric("Total (US$)", total_mundo_display)

    st.markdown("---")
    # --- FIM DO BLOCO DE M√âTRICAS ---

    # ----------------------------------------------------------------------
    # --- NOVO DATAFRAME: EXIBI√á√ÉO DA VCR ---
    # ----------------------------------------------------------------------
    if not comexstat_filtered.empty:
        # 1. C√°lculo da VCR para a sele√ß√£o atual
        # CHAVE: Passando o DataFrame nacional (comexstat_df) como segundo argumento para o contexto
        df_vcr_display = calcular_vcr_dentro_selecao(comexstat_filtered, comexstat_df)

        # Agrega√ß√£o para o DataFrame de exibi√ß√£o (mantendo uma linha por heading/state com VCR)
        df_display = df_vcr_display[
            ["state", "headingCode", "heading", "metricFOB", "VCR"]
        ].copy()

        # Renomear e formatar para exibi√ß√£o
        df_display = df_display.rename(
            columns={
                "state": "Estado",
                "headingCode": "C√≥digo HS",
                "heading": "Descri√ß√£o do Produto",
                "metricFOB": "Valor FOB (US$)",
                "VCR": "VCR (Relev√¢ncia Revelada)",
            }
        )

        df_display["Valor FOB (US$)"] = df_display["Valor FOB (US$)"].apply(
            format_fob_metric
        )
        df_display["VCR (Relev√¢ncia Revelada)"] = df_display[
            "VCR (Relev√¢ncia Revelada)"
        ].round(3)

        st.subheader(
            "Vantagem Comparativa Revelada (VCR) por Produto (Base Nacional/Conjunto)"
        )
        st.dataframe(
            df_display,
            width="stretch",
            column_order=(
                "Estado",
                "C√≥digo HS",
                "Descri√ß√£o do Produto",
                "VCR (Relev√¢ncia Revelada)",
                "Valor FOB (US$)",
            ),
        )

        # ----------------------------------------------------------------------
        # --- REFATORA√á√ÉO DO GR√ÅFICO DE BARRAS (AGRUPAMENTO) ---
        # ----------------------------------------------------------------------

        # Mantendo a l√≥gica de agrupamento em 'Demais/Outros' para o gr√°fico
        # Nota: O gr√°fico ainda usa o valor FOB, mas pode ser mudado para VCR se necess√°rio.
        # Por enquanto, mantemos FOB para representar o valor absoluto de exporta√ß√£o.

        # Agrega o valor FOB por T√≠tulo (Heading) e Estado (State)
        df_agg = (
            comexstat_filtered.groupby(["heading", "state"])["metricFOB"]
            .sum()
            .reset_index()
        )

        total_fob_selection = df_agg["metricFOB"].sum()
        THRESHOLD_PERCENT = 0.02

        df_agg["percentage"] = df_agg["metricFOB"] / total_fob_selection
        df_small = df_agg[df_agg["percentage"] < THRESHOLD_PERCENT].copy()

        if not df_small.empty:
            outros_fob = df_small["metricFOB"].sum()
            outros_data = pd.DataFrame(
                [
                    {
                        "heading": f"Demais/Outros (< {THRESHOLD_PERCENT * 100:.0f}%)",
                        "state": "Agregado",
                        "metricFOB": outros_fob,
                        "percentage": outros_fob / total_fob_selection,
                    }
                ]
            )

            df_large = df_agg[df_agg["percentage"] >= THRESHOLD_PERCENT]
            df_plot = pd.concat([df_large, outros_data], ignore_index=True)
        else:
            df_plot = df_agg.copy()

        # Gr√°fico de barras FOB
        fig = px.bar(
            df_plot.sort_values(by="metricFOB", ascending=False),
            x="heading",
            y="metricFOB",
            color="state",
            title=f"Valor FOB por T√≠tulo (Top Headings + Demais/Outros)",
            labels={
                "heading": "T√≠tulo (Heading)",
                "metricFOB": "Valor FOB (US$)",
                "state": "Estado",
            },
            hover_data={"percentage": ":.2%"},
        )
        st.plotly_chart(fig, use_container_width=True)

# %%
# Aba Harvard Dataverse
with tab_harvard:
    st.header("Dados do Harvard Dataverse")

    # --- FILTROS DENTRO DA ABA ---
    with st.expander("Op√ß√µes de Filtragem"):
        # C√≥pia do DataFrame para filtragem sequencial
        df_filtered = harvard_df.copy()

        # Coluna adicionada para Pa√≠s
        col_year, col_country, col_hs = st.columns(3)

        # 1. Filtro de Ano
        years = sorted(df_filtered["year"].dropna().unique().astype(int).tolist())
        selected_years = col_year.multiselect(
            "Selecione o(s) Ano(s)", years, default=years, key="harvard_year_select"
        )
        if selected_years:
            df_filtered = df_filtered[df_filtered["year"].isin(selected_years)]

        # 2. Filtro de Pa√≠s - IMPLEMENTA√á√ÉO: Default BRA
        # Obter op√ß√µes de pa√≠s (ap√≥s o filtro de ano)
        countries_options = sorted(
            df_filtered["country_iso3_code"].dropna().unique().astype(str).tolist()
        )
        # Definir o default como "BRA" se estiver dispon√≠vel
        default_country = (
            ["BRA"] if "BRA" in countries_options else countries_options[:1]
        )

        selected_countries = col_country.multiselect(
            "Selecione o(s) Pa√≠s(es) (ISO3)",
            options=countries_options,
            default=default_country,  # <--- Prioriza√ß√£o do Brasil
            key="harvard_country_select",
        )
        if selected_countries:
            df_filtered = df_filtered[
                df_filtered["country_iso3_code"].isin(selected_countries)
            ]

        # 3. Filtro de C√≥digo HS
        products = sorted(
            df_filtered["product_hs92_code"].dropna().unique().astype(str).tolist()
        )
        selected_products = col_hs.multiselect(
            "Selecione o(s) C√≥digo(s) HS", products, key="harvard_hs_select"
        )
        if selected_products:
            df_filtered = df_filtered[
                df_filtered["product_hs92_code"].isin(selected_products)
            ]

    # Vari√°vel para o DataFrame filtrado, antes da agrega√ß√£o
    harvard_filtered = df_filtered

    # ----------------------------------------------------------------------
    # --- AGREGA√á√ÉO PARA EXIBI√á√ÉO SUMARIZADA E LIMPA ---
    # ----------------------------------------------------------------------
    if not harvard_filtered.empty:
        # Define as colunas para agrega√ß√£o
        group_cols = ["country_iso3_code", "year"]

        # Agrega√ß√£o: Soma para valores monet√°rios, M√©dia para √≠ndices
        df_aggregated = (
            harvard_filtered.groupby(group_cols)
            .agg(
                {
                    "export_value": "sum",
                    "import_value": "sum",
                    "global_share": "mean",  # M√©dia da participa√ß√£o global
                    "export_rca": "mean",  # M√©dia do VCR de exporta√ß√£o
                    "distance": "mean",  # M√©dia da Dist√¢ncia
                    "cog": "mean",  # M√©dia do COG
                    "pci": "mean",  # M√©dia do PCI
                    "product_id": "count",  # Contagem de produtos (Count)
                }
            )
            .reset_index()
        )

        # Renomear colunas para clareza
        df_aggregated = df_aggregated.rename(
            columns={
                "country_iso3_code": "Pa√≠s (ISO3)",
                "year": "Ano",
                "export_value": "Exporta√ß√£o Total (US$)",
                "import_value": "Importa√ß√£o Total (US$)",
                "global_share": "Share Global M√©dio",
                "export_rca": "VCR M√©dio",
                "distance": "Dist√¢ncia M√©dia",
                "cog": "COG M√©dio",
                "pci": "PCI M√©dio",
                "product_id": "Qtd. Produtos HS",
            }
        )

        # Formata√ß√£o das colunas de valor e arredondamento
        for col in ["Exporta√ß√£o Total (US$)", "Importa√ß√£o Total (US$)"]:
            df_aggregated[col] = df_aggregated[col].apply(
                lambda x: format_fob_metric(x)
                .replace(" Tri", "T")
                .replace(" Bi", "B")
                .replace(" Mi", "M")
            )

        for col in [
            "Share Global M√©dio",
            "VCR M√©dio",
            "Dist√¢ncia M√©dia",
            "COG M√©dio",
            "PCI M√©dio",
        ]:
            df_aggregated[col] = df_aggregated[col].round(3)

        # Exibi√ß√£o do DataFrame AGREGADO
        st.subheader("Tabela Agregada por Pa√≠s e Ano (Sum√°rio)")
        st.dataframe(df_aggregated, width="stretch")

        # --- EXIBI√á√ÉO DETALHADA (OPCIONAL) ---
        with st.expander("Visualizar Detalhes por Produto (Granularidade M√°xima)"):
            st.markdown(
                "Abaixo est√° a tabela na sua granularidade m√°xima, exibindo cada **`product_hs92_code`**."
            )
            st.dataframe(harvard_filtered, width="stretch")

        # ----------------------------------------------------------------------
        # --- NOVO GR√ÅFICO DE BARRA DE PROPOR√á√ÉO DE PRODUTOS ---
        # ----------------------------------------------------------------------
        st.subheader("Distribui√ß√£o de Exporta√ß√£o por Produto (Top 10)")

        # Agrega√ß√£o por C√≥digo HS para obter o valor total de exporta√ß√£o
        df_product_export = (
            harvard_filtered.groupby("product_hs92_code")
            .agg(
                total_export=("export_value", "sum"),
                average_pci=("pci", "mean"),  # Adiciona PCI m√©dio para o hover
            )
            .reset_index()
        )

        # C√°lculo da propor√ß√£o
        total_global_export = df_product_export["total_export"].sum()
        df_product_export["proportion"] = (
            df_product_export["total_export"] / total_global_export
        )

        # Selecionar Top N produtos (ex: Top 10)
        df_plot_product = df_product_export.sort_values(
            by="total_export", ascending=False
        ).head(15)

        # Cria√ß√£o do gr√°fico de barras (propor√ß√£o de exporta√ß√£o)
        fig = px.bar(
            df_plot_product,
            x="product_hs92_code",
            y="proportion",  # Usar a propor√ß√£o no eixo Y
            color="proportion",  # Colorir pela propor√ß√£o
            title="Propor√ß√£o de Exporta√ß√£o (Export Value) por C√≥digo HS",
            labels={
                "product_hs92_code": "C√≥digo HS (Produto)",
                "proportion": "Propor√ß√£o do Total (%)",
                "total_export": "Valor Exportado (US$)",
            },
            hover_data={
                "total_export": True,
                "average_pci": ":.3f",
                "proportion": ":.2%",
            },
            template="plotly_dark",  # Para manter a est√©tica escura
        )

        fig.update_layout(yaxis_tickformat=".0%")  # Formatar eixo Y como porcentagem

        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("Nenhum dado encontrado com os filtros aplicados.")

with tab_comtrade:
    st.header("Dados do Comtrade")

    # --- FILTROS DENTRO DA ABA ---
    with st.expander("Op√ß√µes de Filtragem"):
        df_filtered = comtrade_df.copy()

        col_year, col_hs = st.columns(2)

        # Filtro de ano
        years = sorted(df_filtered["refYear"].dropna().unique().astype(int).tolist())
        selected_years = col_year.multiselect(
            "Selecione o(s) Ano(s)", years, default=years, key="comtrade_year_select"
        )
        if selected_years:
            df_filtered = df_filtered[df_filtered["refYear"].isin(selected_years)]

        # Filtro de produto (c√≥digos HS)
        products = sorted(df_filtered["cmdCode"].dropna().unique().astype(str).tolist())
        selected_products = col_hs.multiselect(
            "Selecione o(s) C√≥digo(s) HS", products, key="comtrade_hs_select"
        )
        if selected_products:
            df_filtered = df_filtered[df_filtered["cmdCode"].isin(selected_products)]

    comtrade_filtered = df_filtered

    st.dataframe(comtrade_filtered, width="stretch")

    if not comtrade_filtered.empty:
        # Gr√°fico de pizza para a distribui√ß√£o do valor prim√°rio por produto
        fig = px.pie(
            comtrade_filtered,
            names="cmdDesc",
            values="primaryValue",
            title="Distribui√ß√£o do Valor Prim√°rio por Descri√ß√£o do Produto",
        )
        st.plotly_chart(fig, use_container_width=True)

# %%
# Aba An√°lise Comparativa
with tab_compare:
    st.header("An√°lise Comparativa de Especializa√ß√£o e Complexidade")
    st.markdown(
        "Consolida√ß√£o de m√©tricas de VCR (Vantagem Comparativa Revelada), Dist√¢ncia e PCI (√çndice de Complexidade de Produtos) por C√≥digo HS."
    )

    # --- 0. Controles de Pesos (Sidebar para tempo real) ---
    st.markdown("### üéöÔ∏è Ajuste de Pesos para o √çndice de Prioridade")
    st.markdown(
        "Utilize os sliders para definir a import√¢ncia de cada m√©trica no **√çndice de Prioridade Ajustado**."
    )

    col_vcr_ce, col_vcr_br, col_vcr_aj, col_pci, col_dist = st.columns(5)

    # Pesos para as 3 VCRs (sub-componentes do '√çndice VCR Composto')
    vcr_ceara_weight = col_vcr_ce.slider(
        "Peso VCR Estadual",
        0.0,
        1.0,
        0.4,
        0.05,
        key="w_vcr_ceara",
        help="Prioriza VCR do estado (Cear√°/Brasil).",
    )
    vcr_brasil_weight = col_vcr_br.slider(
        "Peso VCR Pa√≠s",
        0.0,
        1.0,
        0.3,
        0.05,
        key="w_vcr_brasil",
        help="Prioriza VCR do pa√≠s (Brasil/Mundo).",
    )
    vcr_ajustado_weight = col_vcr_aj.slider(
        "Peso VCR Ajustado",
        0.0,
        1.0,
        0.3,
        0.05,
        key="w_vcr_ajustado",
        help="Prioriza o VCR Ajustado (baseado na Complexidade Local).",
    )

    # Pesos para PCI e Dist√¢ncia (componentes de topo)
    pci_weight = col_pci.slider(
        "Peso PCI",
        0.0,
        1.0,
        0.3,
        0.05,
        key="w_pci",
        help="Prioriza a Complexidade do Produto (PCI).",
    )
    distancia_weight = col_dist.slider(
        "Peso Dist√¢ncia",
        0.0,
        1.0,
        0.4,
        0.05,
        key="w_distancia",
        help="Prioriza a Proximidade dos Parceiros (1 - Dist√¢ncia).",
    )

    # Dicion√°rio de Pesos
    pesos_dict = {
        "vcr_ceara": vcr_ceara_weight,
        "vcr_brasil": vcr_brasil_weight,
        "vcr_ajustado": vcr_ajustado_weight,
        "pci": pci_weight,
        "distancia": distancia_weight,  # M√©trica inversa (Proximidade)
    }

    st.markdown("---")

    # 1. Obter Tabela de Refer√™ncia de C√≥digos HS e Descri√ß√µes
    # Filtra c√≥digos HS inv√°lidos ou vazios
    df_referencia = comexstat_df[["headingCode", "heading"]].drop_duplicates()
    df_referencia = df_referencia.rename(columns={"heading": "Descri√ß√£o"})
    df_referencia = df_referencia[
        df_referencia["headingCode"].notna()
        & (df_referencia["headingCode"] != "0")
        & (df_referencia["headingCode"].str.len() > 1)
    ]

    # 2. C√°lculo e obten√ß√£o das m√©tricas
    df_vcr_ce_br = calcular_vcr_ceara_brasil(comexstat_df)
    df_vcr_br_md = obter_vcr_brasil_mundo(harvard_df)
    df_pci_dist = obter_pci_e_distancia(harvard_df)

    # 3. Consolida√ß√£o dos DataFrames
    df_final = df_referencia.merge(df_vcr_ce_br, on="headingCode", how="left")
    df_final = df_final.merge(df_vcr_br_md, on="headingCode", how="left")
    df_final = df_final.merge(df_pci_dist, on="headingCode", how="left")

    # 4. IMPLEMENTA√á√ÉO: Normaliza√ß√£o dos VCRs Tradicionais (Estadual/Pa√≠s) e Dist√¢ncia (para PCI)
    df_final = normalizar_vcr(df_final, "VCR_Ceara_Brasil")
    df_final = normalizar_vcr(df_final, "VCR_Brasil_Mundo")
    # Normaliza√ß√£o do PCI
    df_final = normalizar_vcr(df_final, "PCI")
    # Normaliza√ß√£o da Dist√¢ncia (Bruta)
    df_final = normalizar_vcr(df_final, "Distancia_Parceiros")

    # 5. IMPLEMENTA√á√ÉO: C√°lculo do VCR Ajustado (Municipal/Setorial) e sua Normaliza√ß√£o (L√≥gica do anexo)
    # Nota: Este √© um PLACEHOLDER, pois os dados municipais/setoriais (Empregos, PIB, etc.) n√£o est√£o carregados.
    df_final = calcular_vcr_ajustado(df_final)

    # 6. IMPLEMENTA√á√ÉO: C√°lculo do √çndice de Prioridade Ajustado
    df_final = calcular_indice_prioridade_ajustado(df_final, pesos_dict)

    # 7. Formata√ß√£o da Tabela
    df_final = df_final.rename(
        columns={
            "headingCode": "C√≥digo HS",
            "VCR_Ceara_Brasil": "VCR estadual (Bruto)",
            "VCR_Ceara_Brasil_NORM": "VCR estadual normalizada",
            "VCR_Brasil_Mundo": "VCR pa√≠s (Bruto)",
            "VCR_Brasil_Mundo_NORM": "VCR pa√≠s normalizada",
            "Distancia_Parceiros": "dist√¢ncia entre parceiros (Bruto)",
            "Distancia_Parceiros_NORM": "dist√¢ncia entre parceiros normalizada",
            "PCI": "PCI (Bruto)",
            "PCI_NORM": "PCI normalizado",
            "VCR_AJUSTADO": "VCR Ajustado (Bruto)",
            "VCR_AJUSTADO_NORM": "VCR Ajustado normalizado",
            "INDICE_PRIORIDADE_AJUSTADO": "√çndice de Prioridade Ajustado",
        }
    )

    # Arredondamento e limpeza
    cols_to_round = [
        "VCR estadual (Bruto)",
        "VCR pa√≠s (Bruto)",
        "VCR estadual normalizada",
        "VCR pa√≠s normalizada",
        "dist√¢ncia entre parceiros (Bruto)",
        "PCI (Bruto)",
        "VCR Ajustado (Bruto)",
        "VCR Ajustado normalizado",
        "PCI normalizado",
        "dist√¢ncia entre parceiros normalizada",
        "√çndice de Prioridade Ajustado",
    ]

    for col in cols_to_round:
        df_final[col] = pd.to_numeric(df_final[col], errors="coerce").round(3)

    # Substituir NaN por 'N/A'
    df_final = df_final.fillna("N/A")

    # Ordena√ß√£o final pela nova m√©trica ajustada
    df_final_sorted = df_final.sort_values(
        by=["√çndice de Prioridade Ajustado"],
        key=lambda x: pd.to_numeric(x, errors="coerce"),
        ascending=False,
    )

    # Exibi√ß√£o da Tabela Consolidada
    st.subheader("Tabela de Especializa√ß√£o e Complexidade Ponderada")
    st.info(
        "A tabela √© ordenada pelo **√çndice de Prioridade Ajustado**, que combina as m√©tricas normalizadas com os pesos definidos nos sliders."
    )

    # Colunas finais a serem exibidas (foco nas m√©tricas normalizadas e no √çndice)
    column_order = [
        "C√≥digo HS",
        "Descri√ß√£o",
        "VCR estadual normalizada",
        "VCR pa√≠s normalizada",
        "VCR Ajustado normalizado",
        "PCI normalizado",
        "dist√¢ncia entre parceiros normalizada",
        "√çndice de Prioridade Ajustado",
    ]

    # Exibir as m√©tricas brutas tamb√©m, em uma se√ß√£o expans√≠vel
    with st.expander("Visualizar M√©trica Brutas"):
        st.dataframe(
            df_final_sorted[
                [
                    "C√≥digo HS",
                    "Descri√ß√£o",
                    "VCR estadual (Bruto)",
                    "VCR pa√≠s (Bruto)",
                    "VCR Ajustado (Bruto)",
                    "PCI (Bruto)",
                    "dist√¢ncia entre parceiros (Bruto)",
                ]
            ],
            width="stretch",
        )

    st.dataframe(
        df_final_sorted[column_order],
        width="stretch",
    )

    # Espa√ßo para os sum√°rios originais
    st.markdown("---")
    st.subheader("Dados Sumarizados (Originais)")

    col1, col2, col3 = st.columns(3)

    # Coluna 1: Resumo ComexStat
    with col1:
        st.subheader("ComexStat")
        st.markdown("Sum√°rio de valores FOB por estado.")
        if not comexstat_df.empty:
            summary = comexstat_df.groupby("state")["metricFOB"].sum().reset_index()
            st.dataframe(summary, width="stretch")

    # Coluna 2: Resumo Harvard
    with col2:
        st.subheader("Harvard Dataverse")
        st.markdown("Total de exporta√ß√£o e importa√ß√£o por ano.")
        if not harvard_df.empty:
            summary = (
                harvard_df.groupby("year")
                .agg({"export_value": "sum", "import_value": "sum"})
                .reset_index()
            )
            st.dataframe(summary, width="stretch")

    # Coluna 3: Resumo Comtrade
    with col3:
        st.subheader("Comtrade")
        st.markdown("Valor prim√°rio total por ano.")
        if not comtrade_df.empty:
            summary = comtrade_df.groupby("refYear")["primaryValue"].sum().reset_index()
            st.dataframe(summary, width="stretch")
